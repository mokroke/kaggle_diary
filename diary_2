20211211
3日ぶりです。なんかちょっと忙しくてできなくて、やり始めるのがちょっとだけ億劫だったけど、やり始めたら実家みたいな安心感があった。普通に楽しいねこれ。
コンペの評価指標のところで加重相関係数っていうのがあってちょっとだけなるほどって思った。どう意味があるかとか今後勉強できたらいいなと思う。
あと、modelを作成するところでinput層の設定についての壁にぶつかった。input層ってなんだかんだ避けてきたけど、そろそろ向き合うべきかなと思ってる。
ゼロから作るディープラーニングで勉強できるんじゃね、もしかしたら、ってちょっと思った。

20211208
dataloadengとfeatureEngineeringのセルの詳細を終わらせた。
少しずつ順調に進めている。ちょっとずつまとめ方もルールが決まってきて、少しみやすくなった気がする。もうちょっと先まで行ったときに関数とかを一気に使うフェーズがくると思うから、見直せるように準備しておきたい。

20211207
DataLoadingのセルについてまとめた。
datatableっていう高速で読み込めるライブラリがあるってことがわかった。

20211206
GPU,TPUのセルが終わった。何がなんだかわかんなかったけど、色々設定する必要があるんだなってことがわかった。
あと、関数はnotebookから見れることもわかったし、わからないなりに調べる方法はあるんだなって思った。
粘り強くわからないところは徹底的に調べるようにしていきたい。わかるところは増えていくはず。

20211205
前回の中でわからなかったtpu.masterについて調べた。
notebook内でクラスだったり、メソッドの中身を見れるのは面白いなって思った。
クラスの中身までみまくってちゃんと理解できるようになりたい。

20211203
`tf.distribute.cluster_resolver.TPUClusterResolver()`
について調べた。なんかapi的な話だった。tpu.master()はちょっとわかんない。

2021/12/02
LBはもうTrainDataの中に入ってるからまじで意味ないけど、意味あるようにしようとしたnotebookがある
[**🪙💲 Proposal for a meaningful LB + Strict LGBM**]([https://www.kaggle.com/julian3833/proposal-for-a-meaningful-lb-strict-lgbm](https://www.kaggle.com/julian3833/proposal-for-a-meaningful-lb-strict-lgbm))
まず読み込むときにLBのは入れないようにしようねってことだった。
てかこのnotebookめっちゃ簡潔で見やすいから、これを参考に細かく見ていってもいいなってちょっと思った。

2021/12/01
かぐるべんきょーかいに出た。NFLの物体検出をやってて、こんな世界もあるんだなと思った。ヘルメットと選手を紐づけるやつらしい。物体検出でヘルメットを検出してから選手の割り当てをするみたい。
どうやるか想像することは全然容易じゃなかったけど、こんなふうに手順を追えばできるんだなって思った。
もう少しまとめて考えたり、コードを全体的に把握できるようになればできるようになるのかなって思った。

2021/11/30
NNのstarterの続きをやった

2021/11/29
NNのstarterをやってみたけど、微妙に書き漏らしのあるコードがあってビビったよね。ちょっとずつ進めてて良かったわ。

2021/11/28
今日は本格的にGPUやTPUについても知る必要があるなと思ったから、GPUについての記事をみて実装しようと思った。そしたら、またdockerの壁が立ちはだかる。dockerやコンテナについても少し勉強中。

2021/11/27
すごい複雑そうに見えるモデルとかあるけど、紐解いていったら意外と単純なものの組み合わせに過ぎなかったりする。特にプリント文とか代入とか入れ替えとか抽出とかそういう地味だけど
コード量が多いやつに囚われがちになると思う。コード量が多いだけで難しいことはしていないって心からそう思うのは時間かかりそうだけど。

2021/11/26
今日もNNのスターターをみてうつしていった。前から気になってたんだけど、 TPUを使うときにinitializeするよね。TPUって使うときはクラウドらしいから初期化しないといけないんだって。なるほどね。
続きはGPUの環境構築について進めようと思う

2021/11/24
model.fitのところで久しぶりにverboseが出てきたから今回はちゃんと調べようと思って調べた(https://www.notion.so/verbose-a0497f2ddb7f4237818ab98da153b455)
verbose=1がdefaultで全部表示。verbose=2はそこからプログレスバーがないバージョン。verbose=0だと表示なしなんだって。
調べてみると簡単だけど、意外に知らないよね。
てか普通にnotebookに書いてあって笑った。

2021/11/23
3日ぶりにどうもこんにちは。
今日はPuregedGroupTimeSeriesSplitについて勉強した。と言ってもGroupTimeSeriesSplitがメインでPurgedの方はよくわからなかった。
GroupTimeSeriesSplitは日にちがtrainとtestで半分にならないように気を付けてくれてるっぽい。それでPurgedの方は期間を設定してるっぽい。
わからんけど。(https://www.notion.so/Purged-Time-Series-CV-ebe82c150156488db1009e6b3f1cca44)これでnotionのページに飛べるよ

2021/11/20
callback関数を使っていたけど、学習率を変化させて行くものを使ってた。まだなんで学習率を変化させるのかどうやって変化させているのかわからないけど、
少しずつ学んでいきたい。
pergedTimeSeriesCVとかいうちょっとまだよくわかんないものあるけど一つずつクリアしていきたい。

2021/11/19
なんかnnのやつ写してたやつと違ったんだけどなんでやろ

2021/11/18
今日は[PurgedGroupTimeSeries CV with Extra Data | NN](https://www.kaggle.com/yamqwe/purgedgrouptimeseries-cv-with-extra-data-nn)を進めていく。
ニューラルネットを使うみたいだから楽しみ。


2021/11/17
今日からG-Researchについてやっていきたいと思う。
参考notebook [G-Research- Starter LGBM Pipeline][~url~](https://www.kaggle.com/julian3833/g-research-starter-lgbm-pipeline)
とりあえず提出することができたからよしとしようかな。
今度はこの人のnotebookが面白そう[1st Place of Jane Street 🏆 ➜ Adapted to Crypto 👌][~url~][https://www.kaggle.com/yamqwe/1st-place-of-jane-street-adapted-to-crypto]
たくさんの手法が載ってるからこれを読んでるだけでも勉強になると思う。当分はこれをコツコツやろうかな。
